import streamlit as st
import pandas as pd
from io import StringIO, BytesIO
from processor import procesar_global

st.set_page_config(page_title="CLAIRPORT ‚Äì Consolidado Global", layout="wide")
st.title("üìä Consolidado Global Aeroportuario ‚Äì CLAIRPORT")

# =====================================================
# üì• LECTORES ROBUSTOS PARA CSV/EXCEL
# =====================================================

def read_generic_csv(uploaded_file):
    raw = uploaded_file.read()
    uploaded_file.seek(0)
    text = raw.decode("latin-1").replace("√Ø¬ª¬ø", "").replace("\ufeff", "")
    sep = ";" if text.count(";") > text.count(",") else ","
    return pd.read_csv(StringIO(text), sep=sep, engine="python")

def read_auditorias_csv(uploaded_file):
    raw = uploaded_file.read()
    uploaded_file.seek(0)
    text = raw.decode("latin-1").replace("√Ø¬ª¬ø", "").replace("\ufeff", "")
    return pd.read_csv(StringIO(text), sep=";", engine="python")

# =====================================================
# üì• CARGA DE ARCHIVOS
# =====================================================

st.header("üì• Cargar Archivos ‚Äì Todos obligatorios")

col1, col2 = st.columns(2)

with col1:
    ventas_file = st.file_uploader("üîµ Ventas (.csv o .xlsx)", type=["csv", "xlsx"])
    performance_file = st.file_uploader("üü¢ Performance (.csv)", type=["csv"])
    auditorias_file = st.file_uploader("üü£ Auditor√≠as (.csv)", type=["csv"])
    offtime_file = st.file_uploader("üü† Off-Time (.csv)", type=["csv"])

with col2:
    duracion90_file = st.file_uploader("üî¥ Duraci√≥n >90 min (.csv)", type=["csv"])
    duracion30_file = st.file_uploader("üü§ Duraci√≥n >30 min (.csv)", type=["csv"])
    inspecciones_file = st.file_uploader("üöó Inspecciones Vehiculares (.xlsx)", type=["xlsx"])
    abandonados_file = st.file_uploader("üü£ Clientes Abandonados (.xlsx)", type=["xlsx"])

st.divider()

# =====================================================
# üìÖ RANGO DE FECHAS
# =====================================================

st.header("üìÖ Seleccionar Rango de Fechas")

col_a, col_b = st.columns(2)
with col_a:
    date_from = st.date_input("üìÜ Desde:", value=None, format="YYYY-MM-DD")
with col_b:
    date_to = st.date_input("üìÜ Hasta:", value=None, format="YYYY-MM-DD")

if not date_from or not date_to:
    st.warning("‚ö† Debes seleccionar ambas fechas para procesar.")
    st.stop()

date_from = pd.to_datetime(date_from)
date_to = pd.to_datetime(date_to)

st.divider()

# =====================================================
# üöÄ PROCESAR
# =====================================================

if st.button("üöÄ Procesar Consolidado Global", type="primary"):

    required = [
        ventas_file, performance_file, auditorias_file, offtime_file,
        duracion90_file, duracion30_file, inspecciones_file, abandonados_file
    ]

    if not all(required):
        st.error("‚ùå Debes subir TODOS los archivos antes de continuar.")
        st.stop()

    # =====================================================
    # üìå LECTURA DE ARCHIVOS
    # =====================================================

    try:
        if ventas_file.name.endswith(".csv"):
            df_ventas = read_generic_csv(ventas_file)
        else:
            df_ventas = pd.read_excel(ventas_file)
    except Exception as e:
        st.error(f"‚ùå Error leyendo Ventas: {e}")
        st.stop()

    try:
        df_performance = read_generic_csv(performance_file)
    except Exception as e:
        st.error(f"‚ùå Error leyendo Performance: {e}")
        st.stop()

    try:
        df_auditorias = read_auditorias_csv(auditorias_file)
    except Exception as e:
        st.error(f"‚ùå Error leyendo Auditor√≠as: {e}")
        st.stop()

    try:
        df_offtime = read_generic_csv(offtime_file)
    except Exception as e:
        st.error(f"‚ùå Error leyendo Off-Time: {e}")
        st.stop()

    try:
        df_dur90 = read_generic_csv(duracion90_file)
    except Exception as e:
        st.error(f"‚ùå Error leyendo Duraci√≥n >90 min: {e}")
        st.stop()

    try:
        df_dur30 = read_generic_csv(duracion30_file)
    except Exception as e:
        st.error(f"‚ùå Error leyendo Duraci√≥n >30 min: {e}")
        st.stop()

    try:
        df_ins = pd.read_excel(inspecciones_file)
    except Exception as e:
        st.error(f"‚ùå Error leyendo Inspecciones: {e}")
        st.stop()

    try:
        df_aband = pd.read_excel(abandonados_file)
    except Exception as e:
        st.error(f"‚ùå Error leyendo Clientes Abandonados (Excel): {e}")
        st.stop()

    # =====================================================
    # üîµ PROCESAMIENTO GLOBAL
    # =====================================================

    try:
        df_diario, df_semanal, df_periodo = procesar_global(
            df_ventas, df_performance, df_auditorias,
            df_offtime, df_dur90, df_dur30,
            df_ins, df_aband,
            date_from, date_to
        )
    except Exception as e:
        st.error(f"‚ùå Error procesando datos: {e}")
        st.stop()

    st.success("‚úÖ Consolidado generado con √©xito")

    st.subheader("üìÖ Diario Consolidado")
    st.dataframe(df_diario, use_container_width=True)

    st.subheader("üìÜ Semanal Consolidado")
    st.dataframe(df_semanal, use_container_width=True)

    st.subheader("üìä Resumen del Periodo")
    st.dataframe(df_periodo, use_container_width=True)

    # =====================================================
    # üì• DESCARGA
    # =====================================================

    output = BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        df_diario.to_excel(writer, index=False, sheet_name="Diario")
        df_semanal.to_excel(writer, index=False, sheet_name="Semanal")
        df_periodo.to_excel(writer, index=False, sheet_name="Periodo")

    st.download_button(
        "üíæ Descargar Consolidado Global",
        data=output.getvalue(),
        file_name="Consolidado_Global.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

else:
    st.info("Carga todos los archivos, selecciona fechas y presiona **Procesar Consolidado Global**.")



