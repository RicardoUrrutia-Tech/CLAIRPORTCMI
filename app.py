import streamlit as st
import pandas as pd
from io import StringIO, BytesIO
from processor import procesar_global

st.set_page_config(page_title="CLAIRPORT â€“ Consolidado Global", layout="wide")
st.title("ğŸ“Š Consolidado Global Aeroportuario â€“ CLAIRPORT")

# =====================================================
# ğŸ“¥ LECTORES ROBUSTOS PARA CSV/EXCEL
# =====================================================

def read_generic_csv(uploaded_file):
    raw = uploaded_file.read()
    uploaded_file.seek(0)
    text = raw.decode("latin-1").replace("Ã¯Â»Â¿", "").replace("\ufeff", "")
    sep = ";" if text.count(";") > text.count(",") else ","
    return pd.read_csv(StringIO(text), sep=sep, engine="python")

def read_auditorias_csv(uploaded_file):
    raw = uploaded_file.read()
    uploaded_file.seek(0)
    text = raw.decode("latin-1").replace("Ã¯Â»Â¿", "").replace("\ufeff", "")
    return pd.read_csv(StringIO(text), sep=";", engine="python")

# =====================================================
# ğŸ“¥ CARGA DE ARCHIVOS
# =====================================================

st.header("ğŸ“¥ Cargar Archivos â€“ Todos obligatorios")

col1, col2 = st.columns(2)

with col1:
    ventas_file = st.file_uploader("ğŸ”µ Ventas (.csv o .xlsx)", type=["csv", "xlsx"])
    performance_file = st.file_uploader("ğŸŸ¢ Performance (.csv)", type=["csv"])
    auditorias_file = st.file_uploader("ğŸŸ£ AuditorÃ­as (.csv)", type=["csv"])
    offtime_file = st.file_uploader("ğŸŸ  Off-Time (.csv)", type=["csv"])

with col2:
    duracion90_file = st.file_uploader("ğŸ”´ DuraciÃ³n >90 min (.csv)", type=["csv"])
    duracion30_file = st.file_uploader("ğŸŸ¤ DuraciÃ³n >30 min (.csv)", type=["csv"])
    inspecciones_file = st.file_uploader("ğŸš— Inspecciones Vehiculares (.xlsx)", type=["xlsx"])
    abandonados_file = st.file_uploader("ğŸ‘¥ Clientes Abandonados (.xlsx)", type=["xlsx"])
    rescates_file = st.file_uploader("ğŸ†˜ Rescates DO Aero (.csv)", type=["csv"])
    whatsapp_file = st.file_uploader("ğŸ’¬ Tickets WhatsApp (.csv)", type=["csv"])

st.divider()

# =====================================================
# ğŸ“… RANGO DE FECHAS
# =====================================================

st.header("ğŸ“… Seleccionar Rango de Fechas")

col_a, col_b = st.columns(2)
with col_a:
    date_from = st.date_input("ğŸ“† Desde:", value=None, format="YYYY-MM-DD")
with col_b:
    date_to = st.date_input("ğŸ“† Hasta:", value=None, format="YYYY-MM-DD")

if not date_from or not date_to:
    st.warning("âš  Debes seleccionar ambas fechas para procesar.")
    st.stop()

date_from = pd.to_datetime(date_from)
date_to = pd.to_datetime(date_to)

st.divider()

# =====================================================
# ğŸš€ PROCESAR
# =====================================================

if st.button("ğŸš€ Procesar Consolidado Global", type="primary"):

    required = [
        ventas_file, performance_file, auditorias_file, offtime_file,
        duracion90_file, duracion30_file, inspecciones_file,
        abandonados_file, rescates_file, whatsapp_file
    ]

    if not all(required):
        st.error("âŒ Debes subir TODOS los archivos antes de continuar (incluido Tickets WhatsApp).")
        st.stop()

    # =====================================================
    # ğŸ“Œ LECTURA DE ARCHIVOS
    # =====================================================

    try:
        if ventas_file.name.endswith(".csv"):
            df_ventas = read_generic_csv(ventas_file)
        else:
            df_ventas = pd.read_excel(ventas_file)
    except Exception as e:
        st.error(f"âŒ Error leyendo Ventas: {e}")
        st.stop()

    try:
        df_performance = read_generic_csv(performance_file)
    except Exception as e:
        st.error(f"âŒ Error leyendo Performance: {e}")
        st.stop()

    try:
        df_auditorias = read_auditorias_csv(auditorias_file)
    except Exception as e:
        st.error(f"âŒ Error leyendo AuditorÃ­as: {e}")
        st.stop()

    try:
        df_offtime = read_generic_csv(offtime_file)
    except Exception as e:
        st.error(f"âŒ Error leyendo Off-Time: {e}")
        st.stop()

    try:
        df_dur90 = read_generic_csv(duracion90_file)
    except Exception as e:
        st.error(f"âŒ Error leyendo DuraciÃ³n >90 min: {e}")
        st.stop()

    try:
        df_dur30 = read_generic_csv(duracion30_file)
    except Exception as e:
        st.error(f"âŒ Error leyendo DuraciÃ³n >30 min: {e}")
        st.stop()

    try:
        df_ins = pd.read_excel(inspecciones_file)
    except Exception as e:
        st.error(f"âŒ Error leyendo Inspecciones: {e}")
        st.stop()

    try:
        df_aband = pd.read_excel(abandonados_file)
    except Exception as e:
        st.error(f"âŒ Error leyendo Clientes Abandonados (Excel): {e}")
        st.stop()

    try:
        df_resc = read_generic_csv(rescates_file)
    except Exception as e:
        st.error(f"âŒ Error leyendo Rescates: {e}")
        st.stop()

    try:
        df_whatsapp = read_generic_csv(whatsapp_file)
    except Exception as e:
        st.error(f"âŒ Error leyendo Tickets WhatsApp: {e}")
        st.stop()

    # =====================================================
    # ğŸ”µ PROCESAMIENTO GLOBAL
    # =====================================================

    try:
        df_diario, df_semanal, df_periodo, df_transpuesta = procesar_global(
            df_ventas, df_performance, df_auditorias,
            df_offtime, df_dur90, df_dur30,
            df_ins, df_aband, df_resc,
            df_whatsapp,
            date_from, date_to
        )
    except Exception as e:
        st.error(f"âŒ Error procesando datos: {e}")
        st.stop()

    st.success("âœ… Consolidado generado con Ã©xito")

    st.subheader("ğŸ“… Diario Consolidado")
    st.dataframe(df_diario, use_container_width=True)

    st.subheader("ğŸ“† Semanal Consolidado")
    st.dataframe(df_semanal, use_container_width=True)

    st.subheader("ğŸ“Š Resumen del Periodo")
    st.dataframe(df_periodo, use_container_width=True)

    st.subheader("ğŸ“ Vista Traspuesta (KPIs x DÃ­a / Semana)")
    st.dataframe(df_transpuesta, use_container_width=True)

    # =====================================================
    # ğŸ“¥ DESCARGA (con estilo Cabify en semanas)
    # =====================================================

    output = BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        df_diario.to_excel(writer, index=False, sheet_name="Diario")
        df_semanal.to_excel(writer, index=False, sheet_name="Semanal")
        df_periodo.to_excel(writer, index=False, sheet_name="Periodo")
        df_transpuesta.to_excel(writer, index=False, sheet_name="Vista_Traspuesta")

        # ğŸ¨ Estilo Cabify (moradul) para columnas de Semana en Vista_Traspuesta
        workbook = writer.book
        ws = writer.sheets["Vista_Traspuesta"]

        week_format = workbook.add_format({
            "bg_color": "#4A2B8D",   # Morado Cabify
            "font_color": "#FFFFFF",
            "bold": True
        })

        # Buscar columnas cuyo encabezado comience con "Semana "
        for col_idx, col_name in enumerate(df_transpuesta.columns):
            if isinstance(col_name, str) and col_name.startswith("Semana "):
                ws.set_column(col_idx, col_idx, 20, week_format)

    st.download_button(
        "ğŸ’¾ Descargar Consolidado Global",
        data=output.getvalue(),
        file_name="Consolidado_Global.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

else:
    st.info("Carga todos los archivos, selecciona fechas y presiona **Procesar Consolidado Global**.")



